{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "def mse_loss(y_true,y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    A simple 2 input Perceptron written as explicitly as possible\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.w1 = np.random.normal()\n",
    "        self.w2 = np.random.normal()\n",
    "        self.w3 = np.random.normal()\n",
    "\n",
    "        self.b1 = np.random.normal()\n",
    "        self.b2 = np.random.normal()\n",
    "    \n",
    "    def feed_forward(self,x):\n",
    "        z1 = self.w1 * x[:,0] + self.w2 * x[:,1] + self.b1\n",
    "        h1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = self.w3 * h1 + self.b2\n",
    "        output = sigmoid(z2)\n",
    "        return output\n",
    "    \n",
    "    def train(self,x_data,y_data,alpha,epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for x,y in zip(x_data,y_data):\n",
    "                z1 = self.w1 * x[0] + self.w2 * x[1] + self.b1\n",
    "                h1 = sigmoid(z1)\n",
    "\n",
    "                z2 = self.w3 * h1 + self.b2\n",
    "                y_pred = sigmoid(z2)\n",
    "                \n",
    "                d_L_d_ypred = - 2 * (y - y_pred)\n",
    "                \n",
    "                #Output Neuron\n",
    "                d_ypred_d_z2 = sigmoid_derivative(z2)\n",
    "                d_z2_d_w3 = h1\n",
    "                d_L_d_w3 = d_L_d_ypred * d_ypred_d_z2 * d_z2_d_w3\n",
    "                d_L_d_b2 = d_L_d_ypred * d_ypred_d_z2\n",
    "                \n",
    "                #Hidden Layer\n",
    "                d_z2_d_h1 = self.w3\n",
    "                d_h1_d_z1 = sigmoid_derivative(z1)\n",
    "                d_z1_d_w2 = x[1]\n",
    "                d_z1_d_w1 = x[0]\n",
    "                d_L_d_w1 = d_L_d_ypred * d_ypred_d_z2 * d_z2_d_h1 * d_h1_d_z1 * d_z1_d_w1\n",
    "                d_L_d_w2 = d_L_d_ypred * d_ypred_d_z2 * d_z2_d_h1 * d_h1_d_z1 * d_z1_d_w2\n",
    "                d_L_d_b1= d_L_d_ypred * d_ypred_d_z2 * d_z2_d_h1 * d_h1_d_z1\n",
    "                \n",
    "                #Updates Weights\n",
    "                self.w1 -= alpha * d_L_d_w1\n",
    "                self.w2 -= alpha * d_L_d_w2\n",
    "                self.w3 -= alpha * d_L_d_w3\n",
    "                self.b1 -= alpha * d_L_d_b1\n",
    "                self.b2 -= alpha * d_L_d_b2\n",
    "            if epoch % 100 == 0:\n",
    "                y_pred =  self.feed_forward(x_data)\n",
    "                loss = mse_loss(y_data,y_pred)\n",
    "                print(\"Epoch %d loss: %.3f\" % (epoch, loss))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Trying to solve a logic OR gate</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.210\n",
      "Epoch 100 loss: 0.075\n",
      "Epoch 200 loss: 0.021\n",
      "Epoch 300 loss: 0.010\n",
      "Epoch 400 loss: 0.006\n",
      "Epoch 500 loss: 0.004\n",
      "Epoch 600 loss: 0.003\n",
      "Epoch 700 loss: 0.003\n",
      "Epoch 800 loss: 0.002\n",
      "Epoch 900 loss: 0.002\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [0,1],\n",
    "    [1,1]\n",
    "])\n",
    "Y = np.array([\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "])\n",
    "NN = Perceptron()\n",
    "NN.train(X,Y,0.3,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06314576, 0.96466155, 0.96453308, 0.98411097])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.feed_forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Trying to solve a logic OR gate</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.345\n",
      "Epoch 100 loss: 0.181\n",
      "Epoch 200 loss: 0.134\n",
      "Epoch 300 loss: 0.055\n",
      "Epoch 400 loss: 0.021\n",
      "Epoch 500 loss: 0.011\n",
      "Epoch 600 loss: 0.007\n",
      "Epoch 700 loss: 0.005\n",
      "Epoch 800 loss: 0.004\n",
      "Epoch 900 loss: 0.003\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [0,1],\n",
    "    [1,1]\n",
    "])\n",
    "Y = np.array([\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "])\n",
    "NN = Perceptron()\n",
    "NN.train(X,Y,0.3,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00965879, 0.04609439, 0.04633098, 0.92233412])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.feed_forward(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
